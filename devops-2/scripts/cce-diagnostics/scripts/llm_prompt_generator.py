#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°
ë¡œë”©ëœ ì§„ë‹¨ í•­ëª©ì„ ê¸°ë°˜ìœ¼ë¡œ LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±
"""

import json
import logging
from typing import List, Dict, Any
from load_diagnostic_items import load_diagnostic_items

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def generate_llm_prompt(item: Dict[str, Any], system_type: str = "Linux") -> str:
    """
    ê°œë³„ ì§„ë‹¨ í•­ëª©ì— ëŒ€í•œ LLM í”„ë¡¬í”„íŠ¸ ìƒì„±

    Args:
        item (Dict[str, Any]): ì§„ë‹¨ í•­ëª©
        system_type (str): ì‹œìŠ¤í…œ íƒ€ì… (Linux, Windows, DB ë“±)

    Returns:
        str: LLM í”„ë¡¬í”„íŠ¸
    """
    cce_id = item.get("CCE_ID", "")
    check_item = item.get("ì ê²€í•­ëª©", "")
    result = item.get("ê²°ê³¼", "")
    status = item.get("í˜„í™©", "")
    improvement = item.get("ê°œì„ ë°©ì•ˆ", "")

    prompt = f"""
ë‹¤ìŒì€ {system_type} ì‹œìŠ¤í…œ ë³´ì•ˆ ì ê²€ ê²°ê³¼ì…ë‹ˆë‹¤.

â— CCE ID: {cce_id}
â— ì ê²€ í•­ëª©: {check_item}
â— ê²°ê³¼: {result}
â— í˜„í™©: {status}
â— ê°œì„ ë°©ì•ˆ: {improvement}

ì§ˆë¬¸:
ì´ í•­ëª©ì˜ ëª©ì ê³¼ ë³´ì•ˆ ì¤‘ìš”ì„±ì„ ì„¤ëª…í•˜ê³ , ì‹¤ì œ {system_type} ì‹œìŠ¤í…œ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì¹˜í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{{
    "ìƒì„¸í•´ì„¤": "ì·¨ì•½ì ì— ëŒ€í•œ ìƒì„¸í•œ ê¸°ìˆ ì  ì„¤ëª…",
    "ì¡°ì¹˜ë°©ë²•": ["1ë‹¨ê³„: ...", "2ë‹¨ê³„: ...", "3ë‹¨ê³„: ..."]
}}
"""
    return prompt


def generate_batch_prompts(
    items: List[Dict[str, Any]], system_type: str = "Linux"
) -> List[Dict[str, Any]]:
    """
    ì—¬ëŸ¬ ì§„ë‹¨ í•­ëª©ì— ëŒ€í•œ LLM í”„ë¡¬í”„íŠ¸ ë°°ì¹˜ ìƒì„±

    Args:
        items (List[Dict[str, Any]]): ì§„ë‹¨ í•­ëª© ë¦¬ìŠ¤íŠ¸
        system_type (str): ì‹œìŠ¤í…œ íƒ€ì…

    Returns:
        List[Dict[str, Any]]: í”„ë¡¬í”„íŠ¸ì™€ ì›ë³¸ ë°ì´í„°ê°€ í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸
    """
    prompts = []

    for i, item in enumerate(items):
        prompt = generate_llm_prompt(item, system_type)

        prompt_data = {
            "index": i,
            "original_item": item,
            "prompt": prompt,
            "system_type": system_type,
        }

        prompts.append(prompt_data)
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {item.get('CCE_ID', 'Unknown')}")

    return prompts


def save_prompts_to_file(prompts: List[Dict[str, Any]], output_file: str):
    """
    ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥

    Args:
        prompts (List[Dict[str, Any]]): í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸
        output_file (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(prompts, f, ensure_ascii=False, indent=2)

        logger.info(f"í”„ë¡¬í”„íŠ¸ ì €ì¥ ì™„ë£Œ: {output_file}")

    except Exception as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì§„ë‹¨ í•­ëª© ë¡œë“œ
    input_file = "output/linux_result.json"
    items = load_diagnostic_items(input_file)

    if not items:
        logger.error("ë¡œë“œí•  ì§„ë‹¨ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‹ {len(items)}ê°œ ì§„ë‹¨ í•­ëª© ë¡œë“œ ì™„ë£Œ")

    # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
    system_type = "Linux"
    prompts = generate_batch_prompts(items, system_type)

    print(f"âœ… {len(prompts)}ê°œ LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")

    # ì²« ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ ì¶œë ¥
    if prompts:
        first_prompt = prompts[0]
        print("\nğŸ“ ì²« ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:")
        print("=" * 50)
        print(first_prompt["prompt"])
        print("=" * 50)

    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    output_file = "output/llm_prompts.json"
    save_prompts_to_file(prompts, output_file)

    print(f"\nğŸ’¾ í”„ë¡¬í”„íŠ¸ ì €ì¥ ì™„ë£Œ: {output_file}")


if __name__ == "__main__":
    main()
